{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has the purpose of finding the best estimator for the underlying data. Therefore gridsearch is used to find the best hyperparameters for the random forests model as well as for the logistic regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ipynb.fs.full.prep_datasets import pipeline_preparation\n",
    "from ipynb.fs.full.feature_eng import pipeline_feature_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scores and gridsearch\n",
    "import random\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load the data, prepare the data & feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"final_df_dec.csv\")\n",
    "df, df_2016 = pipeline_preparation(df)\n",
    "df, X_train, X_test, y_train, y_test = pipeline_feature_eng(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Grid search random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we wanna tune / searching for the best model. Lets see if we could outperform the benchmark mentioned before. This grid represents the best outcome, the intermediat trials are not saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_ranfor(df, X_train, y_train):\n",
    "    \n",
    "    cols = df.columns[0:-1]\n",
    "    estimator = RandomForestClassifier()\n",
    "    grid_search_parameter_space = {\"bootstrap\" : [True],\n",
    "                                   \"class_weight\": [None],\n",
    "                                   \"criterion\":[\"gini\"],\n",
    "                                   \"max_depth\" : [3, 4], \n",
    "                                   \"max_features\" : [10, 12, 14],\n",
    "                                   \"max_leaf_nodes\":[None],\n",
    "                                   \"min_impurity_decrease\":[0],\n",
    "                                   \"min_samples_leaf\" : [9, 12, 15],\n",
    "                                   \"min_samples_split\" : [12, 15],\n",
    "                                   \"min_weight_fraction_leaf\":[0],\n",
    "                                   \"n_estimators\":[10],\n",
    "                                   \"n_jobs\":[-1],\n",
    "                                   \"oob_score\":[False],\n",
    "                                   \"random_state\":[None],\n",
    "                                   \"verbose\":[0],\n",
    "                                   \"warm_start\":[False]}\n",
    "    grid_search = GridSearchCV(\n",
    "                estimator,\n",
    "                grid_search_parameter_space,\n",
    "                cv=5,\n",
    "                scoring=\"roc_auc\", \n",
    "                return_train_score=True)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_estim = grid_search.best_estimator_\n",
    "    print(\"best estimator:\", best_estim)\n",
    "    best_params = grid_search.best_params_\n",
    "    print(\"best params:\", best_params)\n",
    "    best_score = grid_search.best_score_\n",
    "    print(\"best score:\", best_score)\n",
    "\n",
    "    return best_estim, best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=4, max_features=14, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0, min_impurity_split=None,\n",
      "                       min_samples_leaf=9, min_samples_split=12,\n",
      "                       min_weight_fraction_leaf=0, n_estimators=10, n_jobs=-1,\n",
      "                       oob_score=False, random_state=None, verbose=0,\n",
      "                       warm_start=False)\n",
      "best params: {'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'max_features': 14, 'max_leaf_nodes': None, 'min_impurity_decrease': 0, 'min_samples_leaf': 9, 'min_samples_split': 12, 'min_weight_fraction_leaf': 0, 'n_estimators': 10, 'n_jobs': -1, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "best score: 0.9279797728857034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                        max_depth=4, max_features=14, max_leaf_nodes=None,\n",
       "                        min_impurity_decrease=0, min_impurity_split=None,\n",
       "                        min_samples_leaf=9, min_samples_split=12,\n",
       "                        min_weight_fraction_leaf=0, n_estimators=10, n_jobs=-1,\n",
       "                        oob_score=False, random_state=None, verbose=0,\n",
       "                        warm_start=False),\n",
       " {'bootstrap': True,\n",
       "  'class_weight': None,\n",
       "  'criterion': 'gini',\n",
       "  'max_depth': 4,\n",
       "  'max_features': 14,\n",
       "  'max_leaf_nodes': None,\n",
       "  'min_impurity_decrease': 0,\n",
       "  'min_samples_leaf': 9,\n",
       "  'min_samples_split': 12,\n",
       "  'min_weight_fraction_leaf': 0,\n",
       "  'n_estimators': 10,\n",
       "  'n_jobs': -1,\n",
       "  'oob_score': False,\n",
       "  'random_state': None,\n",
       "  'verbose': 0,\n",
       "  'warm_start': False},\n",
       " 0.9279797728857034)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_ranfor(df2, X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Grid search logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_logreg(df, X_train, y_train):\n",
    "    \n",
    "    cols = df.columns[0:-1]\n",
    "    estimator = LogisticRegression()\n",
    "    grid_search_parameter_space = {\"penalty\": ['l1'],\n",
    "                                   \"C\": [2, 5, 7],\n",
    "                                   \"class_weight\":[\"balanced\", None],\n",
    "                                   \"solver\":[\"liblinear\",\"saga\"],\n",
    "                                   \"multi_class\":[\"auto\"],\n",
    "                                   \"max_iter\":[20, 40, 60, 80],\n",
    "                                   \"n_jobs\":[-1],\n",
    "                                   \"verbose\":[0,1]}\n",
    "    grid_search = GridSearchCV(estimator, \n",
    "                               grid_search_parameter_space, \n",
    "                               cv=5, \n",
    "                               scoring = \"roc_auc\", \n",
    "                               return_train_score = True, \n",
    "                               refit = True)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_estim = grid_search.best_estimator_\n",
    "    print(\"best estimator:\", best_estim)\n",
    "    best_params = grid_search.best_params_\n",
    "    print(\"best params:\", best_params)\n",
    "    best_score = grid_search.best_score_\n",
    "    print(\"best score:\", best_score)\n",
    "    \n",
    "    return best_estim, best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid_search_logreg(df, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
